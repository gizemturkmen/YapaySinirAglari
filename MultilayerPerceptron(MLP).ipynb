{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNTk8xo48SxOwL7UdA+fGhg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"uicBpC5Kzx9O","executionInfo":{"status":"ok","timestamp":1681411165928,"user_tz":-180,"elapsed":1001,"user":{"displayName":"Gizem TÃ¼rkmen","userId":"08429542852196844781"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class MLP(nn.Module):\n","    def __init__(self, input_size):\n","        super(MLP, self).__init__()\n","        self.hidden_layer1 = nn.Linear(input_size, 100)\n","        self.relu1 = nn.ReLU()\n","        self.hidden_layer2 = nn.Linear(100, 50)\n","        self.relu2 = nn.ReLU()\n","        self.output_layer = nn.Linear(50, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        a = self.hidden_layer1(x)\n","        a = self.relu1(a)\n","        a = self.hidden_layer2(a)\n","        a = self.relu2(a)\n","        a = self.output_layer(a)\n","        a = self.Sigmoid(a)\n","        return a"]},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","torch.manual_seed(190401049)\n","\n"],"metadata":{"id":"oLyw9XW57KOy"},"execution_count":null,"outputs":[]}]}